{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.    理解文件句柄的概念和文件操作的两种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# 有的时候关闭文件的操作总是会被遗忘，我们有一个使用 \"with\"来操作文件的方式，它是一个上下文的操作，\n",
    "# 会帮你自动的关闭文件，代码示例如下：\n",
    "with open('a.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\n"
     ]
    }
   ],
   "source": [
    "# 除此之外，“with” 可以连续打开多个文件，代码示例如下\n",
    "with open('a.txt', 'r', encoding='utf-8') as f1, open('b.txt', 'r', encoding='utf-8') as f2:\n",
    "    data1 = f1.read()\n",
    "    data2 = f2.read()\n",
    "    print(data1+data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认打开文件的参数说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. 文件打开的字符编码\n",
    "如果不指定字符编码，默认打开文件的字符编码与操作系统相匹配：\n",
    "\n",
    "Windows系统（中国大陆用户）：gbk\n",
    "Liunx系统：utf-8\n",
    "MacOS：utf-8\n",
    "在不指定字符编码的情况下，MacOS系统示例代码："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 文件的打开模式\n",
    "文件默认的打开模式是“t”模式，指的是文本模式，这意味着在该模式下无法打开图片，视频和音频等文件，因为这些是以二进制格式存储的，文本模式是以字符形式存储的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 熟练掌握文件的r,w,a,b四种打开模式，并学会灵活运用\n",
    "操作文件的模式有三种，分别是：“r”，“w”和“a”模式，“r”是只读，“w”是只写，“a”是指追加，默认操作文件大模式是“r”模式，所以默认文件的打开模式是“rt”模式，对于操作文本文件，“t”模式必须与操作文件的三种模式连用，很多时候你看到的，这个“t”经常会省略不写，这是可以的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3 掌握文件操作常用的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 操作文件“r”模式\n",
    "\n",
    "全部读取使用read  \n",
    " 一行一行读文件内容使用readline\n",
    " 全部读取文件内容，存入列表，每行内容为列表的一个元素使用readlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作文件“w”模式\n",
    "# 在“w”只写模式下，当文件存在时，就会清空该文件，代码示例如下：\n",
    "with open('a.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('第一行')\n",
    "    f.write('第二行')\n",
    "# 当文件不存在时，就会创建空文档，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 操作文件“a”模式\n",
    " “a”模式指的是只追加写，当文件不存在时，\n",
    " 创建空文件；当文件存在时，光标直接移至文件末尾，所以，我们在记录日志的时候都会使用“a”模式，代码示例如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二进制模式打开文件的操作\n",
    "###  b”模式基本介绍\n",
    "“b”模式指的是文件打开的模式为“b”模式， 它与“t”模式类似，不能单独使用，必须以“rb”，“wb”或者“ab”模式来使用，“b”模式读写都是以bytes为单位进行的，所以可以理解为“b”模式就是二进制模式。对于普通文本来说是以字符的形式保存的，但是对于图片，视频或者音频等等这些文件则是以二进制形式保存的，所以“t”模式无法读取，代码及报错示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n"
     ]
    }
   ],
   "source": [
    "with open('01.jpg', 'rb', ) as f:\n",
    "    data = f.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作文件的“rb”模式\n",
    "需要说明的一点是，“b”模式也可以读取文本文件，字符的底层都是以二进制形式存储的，只不过你在使用“t”模式读取文本文件的时候open帮你把二进制转成了能够看懂的文本，这是“t”模式的便利之处，但是它有局限性，只能操作文本文件，而“b”模式具有统一性，任何文件底层存储原理都是二进制，这也就是意味着“b”模式可以操作任何文件，代码示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一行第二行\n"
     ]
    }
   ],
   "source": [
    "with open('01.jpg', 'rb', ) as f1, open('a.txt', 'rb') as f2:\n",
    "    img = f1.read()\n",
    "    text = f2.read()\n",
    "    print(text.decode('utf-8'))  # 把bytes转化成utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作文件的“wb”模式\n",
    "“wb”模式也是操作文件“w”模式的一种，当文件存在时，就会清空该文件，当文件不存在时，就会创建空文件，代码示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xef\\xbc\\x8c\\xe4\\xb8\\x96\\xe7\\x95\\x8c'\n",
      "<class 'bytes'>\n",
      "你好，世界\n"
     ]
    }
   ],
   "source": [
    "# wb模式写入\n",
    "with open('a.txt', 'wb') as f:\n",
    "    msg = '你好，世界'\n",
    "    f.write(msg.encode('utf-8'))  # 指定写入文件的字符编码\n",
    "\n",
    "# rb模式读取\n",
    "with open('a.txt', 'rb') as f:\n",
    "    data = f.read()\n",
    "    print(data)\n",
    "    print(type(data))\n",
    "    print(data.decode('utf-8'))  # 指定读取文件的字符编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "操作文件的“ab”模式\n",
    "“ab”模式指的是以二进制形式追加写，与操作文件的“a”模式同理，代码示例如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.    这一张是用Python代码来操作硬件，准确的说是操作计算机的硬盘，目的就是为了让我们的数据能够永久的保存\n",
    "2.    文件的内容可能还会有100G，但是内存也许只有32G，确切的说，一般硬盘中的数据会远大于内存，所以当我们操作文件的时候要考虑硬件的承受能力，软件的性能极限要依托的硬件的基础之上\n",
    "\n",
    "尤其在一些机器学习处理数据的时候，我们经常要使用分块读取数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 练习\n",
    "好，让我们来做一个简单的 NLP（自然语言处理）任务。如果你对此不太了解也没有影响，我会带你一步步完成这个任务。\n",
    "\n",
    "首先，我们要清楚NLP任务的基本步骤，也就是下面的四步：\n",
    "\n",
    "读取文件；\n",
    "\n",
    "去除所有标点符号和换行符，并把所有大写变成小写；\n",
    "\n",
    "合并相同的词，统计每个词出现的频率，并按照词频从大到小排序；\n",
    "\n",
    "将结果按行输出到文件 out.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件# \n",
    "\n",
    "import re\n",
    "with open('in.txt','r',encoding='utf-8') as f:\n",
    "    data=f.read()\n",
    "\n",
    "# 去掉标点和换行符  应该用正则表达\n",
    "newdata=re.sub(r'[^\\w]',' ',data)\n",
    "# 大写换小写\n",
    "newdata=newdata.lower()\n",
    "# 生成所有单词的列表\n",
    "newdata=newdata.split(' ')\n",
    "# 合并相同的词\n",
    "\n",
    "# 遗漏了一步： 去除空白单词\n",
    "newdata=filter(None,newdata)\n",
    "\n",
    "word_cnt={}\n",
    "for word in newdata:\n",
    "    if word not in word_cnt:\n",
    "        word_cnt[word]=0\n",
    "    word_cnt[word]+=1\n",
    "# 统计词频 并从小到大排序\n",
    "word_cnt=sorted(word_cnt.items(),key=lambda x:x[1],reverse=True)   \n",
    "# 将结果输出到out.txt\n",
    "with open('out.txt','w',encoding='utf-8') as f1:\n",
    "    for word,freq in word_cnt:\n",
    "        f1.write('{} {} \\n'.format(word,freq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你不用太关心 parse() 函数的具体实现，你只需要知道，它做的事情是把输入的 text 字符串，转化为我们需要的排序后的词频统计。而 sorted_word_cnt 则是一个二元组的列表（list of tuples）。\n",
    "\n",
    "首先我们需要先了解一下，计算机中文件访问的基础知识。事实上，计算机内核（kernel）对文件的处理相对比较复杂，涉及到内核模式、虚拟文件系统、锁和指针等一系列概念，这些内容我不会深入讲解，我只说一些基础但足够使用的知识。\n",
    "\n",
    "我们先要用open() 函数拿到文件的指针。其中，第一个参数指定文件位置（相对位置或者绝对位置）；第二个参数，如果是 'r'表示读取，如果是'w' 则表示写入，当然也可以用 'rw' ，表示读写都要。a 则是一个不太常用（但也很有用）的参数，表示追加（append），这样打开的文件，如果需要写入，会从原始文件的最末尾开始写入。\n",
    "\n",
    "这里我插一句，在 Facebook 的工作中，代码权限管理非常重要。如果你只需要读取文件，就不要请求写入权限。这样在某种程度上可以降低 bug 对整个系统带来的风险。\n",
    "\n",
    "好，回到我们的话题。在拿到指针后，我们可以通过 read() 函数，来读取文件的全部内容。代码 text = fin.read() ，即表示把文件所有内容读取到内存中，并赋值给变量 text。这么做自然也是有利有弊：\n",
    "\n",
    "优点是方便，接下来我们可以很方便地调用 parse 函数进行分析；\n",
    "\n",
    "缺点是如果文件过大，一次性读取可能造成内存崩溃。\n",
    "\n",
    "这时，我们可以给 read 指定参数 size ，用来表示读取的最大长度。还可以通过 readline() 函数，每次读取一行，这种做法常用于数据挖掘（Data Mining）中的数据清洗，在写一些小的程序时非常轻便。如果每行之间没有关联，这种做法也可以降低内存的压力。而write() 函数，可以把参数中的字符串输出到文件中，也很容易理解。\n",
    "\n",
    "这里我需要简单提一下 with 语句（后文会详细讲到）。open() 函数对应于 close() 函数，也就是说，如果你打开了文件，在完成读取任务后，就应该立刻关掉它。而如果你使用了 with 语句，就不需要显式调用 close()。在 with 的语境下任务执行完毕后，close() 函数会被自动调用，代码也简洁很多。\n",
    "\n",
    "最后需要注意的是，所有 I/O 都应该进行错误处理。因为 I/O 操作可能会有各种各样的情况出现，而一个健壮（robust）的程序，需要能应对各种情况的发生，而不应该崩溃（故意设计的情况除外）。\n",
    "\n",
    "## JSON 序列化与实战\n",
    "最后，我来讲一个和实际应用很贴近的知识点。\n",
    "\n",
    "JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，它的设计意图是把所有事情都用设计的字符串来表示，这样既方便在互联网上传递信息，也方便人进行阅读（相比一些 binary 的协议）。JSON 在当今互联网中应用非常广泛，也是每一个用 Python程序员应当熟练掌握的技能点。\n",
    "\n",
    "设想一个情景，你要向交易所购买一定数额的股票。那么，你需要提交股票代码、方向（买入/卖出）、订单类型（市价/限价）、价格（如果是限价单）、数量等一系列参数，而这些数据里，有字符串，有整数，有浮点数，甚至还有布尔型变量，全部混在一起并不方便交易所解包。\n",
    "\n",
    "那该怎么办呢？\n",
    "\n",
    "其实，我们要讲的JSON ，正能解决这个场景。你可以把它简单地理解为两种黑箱：\n",
    "\n",
    "第一种，输入这些杂七杂八的信息，比如Python 字典，输出一个字符串；\n",
    "\n",
    "第二种，输入这个字符串，可以输出包含原始信息的 Python 字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after json serialization\n",
      "type of params_str = <class 'str'>, params_str = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n",
      "after json deserialization\n",
      "type of original_params = <class 'dict'>, original_params = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "params = {\n",
    "    'symbol': '123456',\n",
    "    'type': 'limit',\n",
    "    'price': 123.4,\n",
    "    'amount': 23\n",
    "}\n",
    "\n",
    "params_str = json.dumps(params)\n",
    "\n",
    "print('after json serialization')\n",
    "print('type of params_str = {}, params_str = {}'.format(type(params_str), params))\n",
    "\n",
    "original_params = json.loads(params_str)\n",
    "\n",
    "print('after json deserialization')\n",
    "print('type of original_params = {}, original_params = {}'.format(type(original_params), original_params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，\n",
    "\n",
    "json.dumps() 这个函数，接受 Python 的基本数据类型，然后将其序列化为 string；\n",
    "\n",
    "而json.loads() 这个函数，接受一个合法字符串，然后将其反序列化为 Python 的基本数据类型。\n",
    "\n",
    "是不是很简单呢？\n",
    "\n",
    "不过还是那句话，请记得加上错误处理。不然，哪怕只是给 json.loads() 发送了一个非法字符串，而你没有 catch 到，程序就会崩溃了。\n",
    "\n",
    "到这一步，你可能会想，如果我要输出字符串到文件，或者从文件中读取JSON字符串，又该怎么办呢？\n",
    "\n",
    "是的，你仍然可以使用上面提到的 open() 和 read()/write() ，先将字符串读取/输出到内存，再进行JSON编码/解码，当然这有点麻烦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after json deserialization\n",
      "type of original_params = <class 'dict'>, original_params = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "params = {\n",
    "    'symbol': '123456',\n",
    "    'type': 'limit',\n",
    "    'price': 123.4,\n",
    "    'amount': 23\n",
    "}\n",
    "\n",
    "with open('params.json', 'w') as fout:\n",
    "    params_str = json.dump(params, fout)\n",
    "\n",
    "with open('params.json', 'r') as fin:\n",
    "    original_params = json.load(fin)\n",
    "\n",
    "print('after json deserialization')\n",
    "print('type of original_params = {}, original_params = {}'.format(type(original_params), original_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，我们就简单清晰地实现了读写 JSON 字符串的过程。当开发一个第三方应用程序时，你可以通过 JSON 将用户的个人配置输出到文件，方便下次程序启动时自动读取。这也是现在普遍运用的成熟做法。\n",
    "\n",
    "那么 JSON 是唯一的选择吗？显然不是，它只是轻量级应用中最方便的选择之一。据我所知，在 Google，有类似的工具叫做Protocol Buffer，当然，Google 已经完全开源了这个工具，你可以自己了解一下使用方法。\n",
    "\n",
    "相比于 JSON，它的优点是生成优化后的二进制文件，因此性能更好。但与此同时，生成的二进制序列，是不能直接阅读的。它在 TensorFlow 等很多对性能有要求的系统中都有广泛的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "这节课，我们主要学习了 Python 的普通 I/O和文件 I/O，同时了解了 JSON 序列化的基本知识，并通过具体的例子进一步掌握。再次强调一下需要注意的几点：\n",
    "\n",
    "I/O 操作需谨慎，一定要进行充分的错误处理，并细心编码，防止出现编码漏洞；\n",
    "\n",
    "编码时，对内存占用和磁盘占用要有充分的估计，这样在出错时可以更容易找到原因；\n",
    "\n",
    "JSON序列化是很方便的工具，要结合实战多多练习；\n",
    "\n",
    "代码尽量简洁、清晰，哪怕是初学阶段，也要有一颗当元帅的心。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考题\n",
    "最后，我给你留了两道思考题。\n",
    "\n",
    "## 第一问：\n",
    "你能否把NLP例子中的 word count 实现一遍？不过这次，in.txt 可能非常非常大（意味着你不能一次读取到内存中），而 output.txt 不会很大（意味着重复的单词数量很多）。\n",
    "\n",
    "提示：你可能需要每次读取一定长度的字符串，进行处理，然后再读取下一次的。但是如果单纯按照长度划分，你可能会把一个单词隔断开，所以需要细心处理这种边界情况。\n",
    "\n",
    "## 第二问\n",
    "你应该使用过类似百度网盘、Dropbox等网盘，但是它们可能空间有限（比如 5GB）。如果有一天，你计划把家里的 100GB 数据传送到公司，可惜你没带 U 盘，于是你想了一个主意：\n",
    "\n",
    "每次从家里向 Dropbox 网盘写入不超过 5GB 的数据，而公司电脑一旦侦测到新数据，就立即拷贝到本地，然后删除网盘上的数据。等家里电脑侦测到本次数据全部传入公司电脑后，再进行下一次写入，直到所有数据都传输过去。\n",
    "\n",
    "根据这个想法，你计划在家写一个 server.py，在公司写一个 client.py 来实现这个需求。\n",
    "\n",
    "提示：我们假设每个文件都不超过 5GB。\n",
    "\n",
    "你可以通过写入一个控制文件（config.json）来同步状态。不过，要小心设计状态，这里有可能产生 race condition。\n",
    "\n",
    "你也可以通过直接侦测文件是否产生，或者是否被删除来同步状态，这是最简单的做法。\n",
    "\n",
    "不要担心难度问题，尽情写下你的思考，最终代码我也会为你准备好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一题 \n",
    "# 读取文件# \n",
    "\n",
    "import re\n",
    "with open('in.txt','r',encoding='utf-8') as f:\n",
    "    data=f.read()\n",
    "\n",
    "# 去掉标点和换行符  应该用正则表达\n",
    "newdata=re.sub(r'[^\\w]',' ',data)\n",
    "# 大写换小写\n",
    "newdata=newdata.lower()\n",
    "# 生成所有单词的列表\n",
    "newdata=newdata.split(' ')\n",
    "# 合并相同的词\n",
    "\n",
    "# 遗漏了一步： 去除空白单词\n",
    "newdata=filter(None,newdata)\n",
    "\n",
    "word_cnt={}\n",
    "for word in newdata:\n",
    "    if word not in word_cnt:\n",
    "        word_cnt[word]=0\n",
    "    word_cnt[word]+=1\n",
    "# 统计词频 并从小到大排序\n",
    "word_cnt=sorted(word_cnt.items(),key=lambda x:x[1],reverse=True)   \n",
    "# 将结果输出到out.txt\n",
    "with open('out.txt','w',encoding='utf-8') as f1:\n",
    "    for word,freq in word_cnt:\n",
    "        f1.write('{} {} \\n'.format(word,freq))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
